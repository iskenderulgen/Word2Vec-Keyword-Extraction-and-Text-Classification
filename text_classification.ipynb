{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c458f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import Tokenizer, StringIndexer, Word2VecModel, IndexToString, Normalizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "# To simulate a cluster environment, change the instance size to test multi instance performance\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.master(\"local[*]\")\n",
    "    .appName(\"Spark-Word2Vec\")\n",
    "    .config(\"spark.driver.memory\", \"20g\")\n",
    "    # .config(\"spark.driver.cores\", \"2\")\n",
    "    # .config(\"spark.executor.cores\", \"2\")\n",
    "    # .config(\"spark.executor.memory\", \"2g\")\n",
    "    # .config(\"spark.driver.maxResultSize\", \"3g\")\n",
    "    # .config(\"spark.executor.instances\", \"2\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326679b0",
   "metadata": {},
   "source": [
    "# 1-load train data and word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2042ccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = spark.read.parquet(\"data/keywords.parquet\")\n",
    "\n",
    "word2vec_model = Word2VecModel.load(\"data/word2vec_model\")\n",
    "\n",
    "train_data.show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885899f7",
   "metadata": {},
   "source": [
    "## 1.1-Tokenizde the training data and vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78b1b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text for word2vec vectorization\n",
    "train_data = Tokenizer(inputCol=\"word\", outputCol=\"filtered_tokens\").transform(train_data)\n",
    "\n",
    "# Use word2vec to transform the tokens into vectors\n",
    "train_data = word2vec_model.transform(train_data)\n",
    "\n",
    "# Use String indexer to convert the string labels into numerical labels\n",
    "string_indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_index\").fit(train_data)\n",
    "train_data = string_indexer.transform(train_data)\n",
    "\n",
    "train_data.show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f502827a",
   "metadata": {},
   "source": [
    "# 2-Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe9b772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression model\n",
    "\n",
    "lr_model = LogisticRegression(\n",
    "    featuresCol=\"word2vec_features\",\n",
    "    labelCol=\"label_index\",\n",
    "    maxIter=500,\n",
    "    regParam=0.3,\n",
    "    elasticNetParam=0.8,\n",
    "    standardization=True,\n",
    ").fit(train_data)\n",
    "\n",
    "# Evaluate the model\n",
    "trainingSummary = lr_model.summary\n",
    "\n",
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "\n",
    "print(\n",
    "    \"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "    % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5723b43",
   "metadata": {},
   "source": [
    "# 3-Test the model with unseed data to classify sentences\n",
    "## 3-1. Read the test data and filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f14310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON lines file\n",
    "comments = (\n",
    "    spark.read.json(\"data/RC_2010-07\")\n",
    "    .select(\"body\", \"subreddit\")\n",
    "    .where(\"body != '[deleted]' AND body != '[removed]'\")\n",
    "    # Filter by subreddits of interest\n",
    "    .where(F.col(\"subreddit\").isin(\"Music\", \"gaming\", \"politics\", \"programming\", \"science\"))\n",
    "    # Replace newline and carriage return characters with a space\n",
    "    .withColumn(\"body\", F.regexp_replace(F.col(\"body\"), \"[\\\\r\\\\n]+\", \" \"))\n",
    "    # Remove URLs (matches strings starting with http or https)\n",
    "    .withColumn(\"body\", F.regexp_replace(F.col(\"body\"), \"https?://\\\\S+\", \"\"))\n",
    "    # Remove characters that are not letters, digits, whitespace, or apostrophes\n",
    "    .withColumn(\"body\", F.regexp_replace(F.col(\"body\"), \"[^a-zA-Z0-9\\\\s']\", \"\"))\n",
    "    # lowercase the subreddit column\n",
    "    .withColumn(\"subreddit\", F.lower(F.col(\"subreddit\")))\n",
    ")\n",
    "\n",
    "comments.show(5, truncate=50)\n",
    "\n",
    "# Get basic statistics\n",
    "print(f\"Number of records: {comments.count()}\")\n",
    "print(f\"Number of columns: {len(comments.columns)}\")\n",
    "print(comments.groupBy(\"subreddit\").count().show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eda8cc1",
   "metadata": {},
   "source": [
    "## 3.2-Tokenize and Vectorize for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2092f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text for word2vec vectorization\n",
    "comments = Tokenizer(inputCol=\"body\", outputCol=\"filtered_tokens\").transform(comments)\n",
    "\n",
    "# Use word2vec to transform the tokens into vectors\n",
    "comments = word2vec_model.transform(comments)\n",
    "\n",
    "comments.show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1a8c41",
   "metadata": {},
   "source": [
    "## 3.3-Classify new data using Lr model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eeab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_model.transform(comments)\n",
    "\n",
    "predictions.show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f41ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract labels from the StringIndexer you used on training data\n",
    "labels = string_indexer.labels\n",
    "\n",
    "# now apply IndexToString transformer with the specified labels\n",
    "predictions = IndexToString(\n",
    "    inputCol=\"prediction\", \n",
    "    outputCol=\"label\", \n",
    "    labels=labels\n",
    ").transform(predictions)\n",
    "\n",
    "predictions.show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0788018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit an indexer on the actual subreddit column\n",
    "predictions = (\n",
    "    StringIndexer(inputCol=\"subreddit\", outputCol=\"subreddit_index\")\n",
    "    .fit(predictions)\n",
    "    .transform(predictions)\n",
    ")\n",
    "\n",
    "\n",
    "# Similarly, convert the predicted label to an index\n",
    "predictions = (\n",
    "    StringIndexer(inputCol=\"label\", outputCol=\"label_index\")\n",
    "    .fit(predictions)\n",
    "    .transform(predictions)\n",
    ")\n",
    "\n",
    "\n",
    "predictions.show(5, truncate=50)\n",
    "\n",
    "# Evaluate using Spark's internal mechanism (accuracy metric)\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"subreddit_index\", predictionCol=\"label_index\", metricName=\"accuracy\"\n",
    ")\n",
    "accuracy_indexed = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy (indexed comparison): {accuracy_indexed}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark-word2vec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
